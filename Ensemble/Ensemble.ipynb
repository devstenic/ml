{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPaGC0Cc7nGg"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIxYnScs7ust"
      },
      "source": [
        "### Exercise 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnycgW_fskRt"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LlrbhQhu1Iz"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "data_set = iris.data[0:len(iris.target)-20,:]\n",
        "labels = iris.target[0:len(iris.target)-20]\n",
        "unique_labels = np.unique(iris.target)\n",
        "\n",
        "test_data_set = iris.data[-20:,:]\n",
        "test_labels = iris.target[-20:]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whpwkp9Jt6my"
      },
      "source": [
        "listOfClasifiers = [LinearRegression(), KNeighborsClassifier(), SVC(), DecisionTreeClassifier(), GaussianNB(),QuadraticDiscriminantAnalysis()]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEpW9c_Csy-D",
        "outputId": "e795cf2f-1481-4e2d-f213-0bb781f2f3b3"
      },
      "source": [
        "def build_classifiers(listOfClasifiers, data_set, labels):\n",
        "\n",
        "    return [clasifier.fit(data_set, labels) for clasifier in listOfClasifiers] # and here\n",
        "\n",
        "print(build_classifiers(listOfClasifiers, data_set, labels))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7Uz5K7Rs8sv"
      },
      "source": [
        "def build_stacked_classifier(classifiers):\n",
        "    output = []\n",
        "    for classifier in classifiers:\n",
        "        output.append(classifier.predict(data_set))\n",
        "    output = np.array(output).reshape((130,3))\n",
        "    \n",
        "    # stacked classifier part:\n",
        "    stacked_classifier = DecisionTreeClassifier() # set here\n",
        "    stacked_classifier.fit(output.reshape((130,3)), labels.reshape((130,)))\n",
        "    test_set = []\n",
        "    for classifier in classifiers:\n",
        "        test_set.append(classifier.predict(test_data_set))\n",
        "    test_set = np.array(test_set).reshape((len(test_set[0]),3))\n",
        "    predicted = stacked_classifier.predict(test_set)\n",
        "    return predicted"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLhCx22PzhyG"
      },
      "source": [
        "from itertools import combinations"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NmEBdUQtAvX",
        "outputId": "17cace57-f77a-4f41-cdaf-c6aa180adeb4"
      },
      "source": [
        "classifiers = build_classifiers(listOfClasifiers, data_set, labels)\n",
        "results = []\n",
        "for i in combinations(classifiers, 3):\n",
        "  predicted = build_stacked_classifier(i)\n",
        "  print(i)\n",
        "  accuracy = accuracy_score(test_labels, predicted)\n",
        "  results.append([i, accuracy])\n",
        "\n",
        "maxValue = max([i[1], index] for index, i in enumerate(results))\n",
        "\n",
        "bestResult = results[maxValue[1]]\n",
        "\n",
        "print(bestResult)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), GaussianNB(priors=None, var_smoothing=1e-09))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), GaussianNB(priors=None, var_smoothing=1e-09))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False), GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'))\n",
            "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), GaussianNB(priors=None, var_smoothing=1e-09))\n",
            "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), GaussianNB(priors=None, var_smoothing=1e-09))\n",
            "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), GaussianNB(priors=None, var_smoothing=1e-09))\n",
            "(SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False), GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "(DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=None, splitter='best'), GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001))\n",
            "[(KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "                     weights='uniform'), GaussianNB(priors=None, var_smoothing=1e-09), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,\n",
            "                              store_covariance=False, tol=0.0001)), 0.85]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUmk_t4H7zMl"
      },
      "source": [
        "### Exercise 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26VKf76C751m"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# prepare data set\n",
        "\n",
        "def generate_data(sample_number, feature_number, label_number):\n",
        "    data_set = np.random.random_sample((sample_number, feature_number))\n",
        "    labels = np.random.choice(label_number, sample_number)\n",
        "    return data_set, labels\n",
        "\n",
        "labels = 2\n",
        "dimension = 2\n",
        "test_set_size = 1000\n",
        "train_set_size = 5000\n",
        "train_set, train_labels = generate_data(train_set_size, dimension, labels)\n",
        "test_set, test_labels = generate_data(test_set_size, dimension, labels)\n",
        "\n",
        "# init weights\n",
        "number_of_iterations = 10\n",
        "weights = np.ones((test_set_size,)) / test_set_size\n",
        "\n",
        "\n",
        "def train_model(classifier, weights):\n",
        "    return classifier.fit(X=test_set, y=test_labels, sample_weight=weights)\n",
        "\n",
        "def calculate_error(model):\n",
        "    predicted = model.predict(test_set)\n",
        "    I=calculate_accuracy_vector(predicted, test_labels)\n",
        "    Z=np.sum(I)\n",
        "    return (1+Z)/1.0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3h_MV6x6EhRT"
      },
      "source": [
        "def calculate_accuracy(predicted, labels):\n",
        "    result = []\n",
        "\n",
        "    for i in range(len(predicted)):\n",
        "      result.append(0) if predicted[i] == labels[i] else result.append(1)\n",
        "\n",
        "    return result\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmanqiFW8HPU"
      },
      "source": [
        "def set_new_weights(model):\n",
        "    accuracy_vector = np.array(calculate_accuracy(model.predict(test_set), test_labels))\n",
        "    return (accuracy_vector + 1) / accuracy_vector.sum() "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaXL92s38I1p",
        "outputId": "c3e5d60c-29c3-4e4e-8c58-e461629de620"
      },
      "source": [
        "classifier = DecisionTreeClassifier(max_depth=1, random_state=1)\n",
        "classifier.fit(X=train_set, y=train_labels)\n",
        "alphas = []\n",
        "classifiers = []\n",
        "for iteration in range(number_of_iterations):\n",
        "    model = train_model(classifier, weights)\n",
        "    weights = set_new_weights(model)\n",
        "    classifiers.append(model)\n",
        "\n",
        "print(weights)\n",
        "\n",
        "\n",
        "validate_x, validate_label = generate_data(1, dimension, labels)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00393701 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.0019685  0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.0019685  0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.00393701 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.00393701 0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.00393701 0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.00393701 0.0019685  0.0019685  0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.00393701 0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.0019685  0.0019685  0.00393701 0.0019685\n",
            " 0.00393701 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.00393701 0.00393701\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.00393701 0.00393701 0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.0019685  0.00393701 0.00393701 0.00393701\n",
            " 0.0019685  0.00393701 0.0019685  0.00393701 0.0019685  0.0019685\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.0019685  0.00393701\n",
            " 0.0019685  0.00393701 0.00393701 0.0019685  0.0019685  0.0019685\n",
            " 0.0019685  0.0019685  0.00393701 0.00393701]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXBVa2Ap8KF3"
      },
      "source": [
        "validate_x, validate_label = generate_data(1, dimension, labels)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BqI2EGHX8LYp"
      },
      "source": [
        "def get_prediction(x):\n",
        "   return classifiers[-1].predict(x)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CVuVSaE8MsR",
        "outputId": "9e27ae5d-ee53-4a8b-c308-778d4a9cc669"
      },
      "source": [
        "prediction = get_prediction(validate_x)[0]\n",
        "\n",
        "print(prediction)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}